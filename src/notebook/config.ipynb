{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a107475",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"..\")))\n",
    "from lang_chain.llm import llm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "427bd47b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æ‚¨å¥½ï¼å¾ˆé«˜å…´è§åˆ°æ‚¨ï¼æˆ‘æ˜¯æ‚¨çš„AIåŠ©æ‰‹ï¼Œæœ‰ä»€ä¹ˆæˆ‘å¯ä»¥å¸®æ‚¨çš„å—ï¼ŸğŸ˜Š\n"
     ]
    }
   ],
   "source": [
    "response = llm.invoke(\"ä½ å¥½\")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "68aa59ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ä½ å¥½ï¼å¾ˆé«˜å…´è§åˆ°ä½  ğŸ˜Š  \n",
      "æœ‰ä»€ä¹ˆå¯ä»¥å¸®ä½ çš„å—ï¼Ÿæ— è®ºæ˜¯é—®é¢˜ã€å»ºè®®ï¼Œè¿˜æ˜¯æƒ³èŠèŠå¤©ï¼Œæˆ‘éƒ½åœ¨è¿™é‡Œç­‰ä½ ï¼"
     ]
    }
   ],
   "source": [
    "stream = llm.stream(\"ä½ å¥½\")\n",
    "for chunk in stream:\n",
    "    print(chunk.content, end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d539e004",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_stream(stream):\n",
    "    for chunk in stream:\n",
    "        print(chunk.content, end=\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f783ad78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "æˆ‘ç›®å‰æœ‰ä¸€ä¸ªå·¥å…·å¯ä»¥ä½¿ç”¨ï¼š\n",
      "\n",
      "**æ•°å­¦è®¡ç®—å·¥å…· (calculate)**\n",
      "- åŠŸèƒ½ï¼šæ‰§è¡Œæ•°å­¦è®¡ç®—\n",
      "- å‚æ•°ï¼šexpressionï¼ˆå¿…éœ€ï¼‰- éœ€è¦è®¡ç®—çš„æ•°å­¦è¡¨è¾¾å¼ï¼Œç±»å‹ä¸ºå­—ç¬¦ä¸²\n",
      "\n",
      "ä¾‹å¦‚ï¼Œä½ å¯ä»¥è®©æˆ‘è®¡ç®—ï¼š\n",
      "- ç®€å•çš„åŠ å‡ä¹˜é™¤ï¼š`2 + 3 * 4`\n",
      "- å¤æ‚çš„è¡¨è¾¾å¼ï¼š`(1 + 2) * (3 + 4) / 2`\n",
      "- å¹³æ–¹ã€å¼€æ–¹ç­‰ï¼š`sqrt(16)` æˆ– `2^3`\n",
      "\n",
      "æœ‰ä»€ä¹ˆæ•°å­¦è®¡ç®—éœ€è¦æˆ‘å¸®å¿™çš„å—ï¼Ÿ"
     ]
    }
   ],
   "source": [
    "from langchain.tools import tool\n",
    "\n",
    "\n",
    "@tool\n",
    "def calculate(expression: str) -> str:\n",
    "    \"\"\"æ‰§è¡Œæ•°å­¦è®¡ç®—\"\"\"\n",
    "    return str(eval(expression))\n",
    "\n",
    "\n",
    "llm_with_tools = llm.bind_tools([calculate])\n",
    "\n",
    "stream = llm_with_tools.stream(\"ä½ æœ‰ä»€ä¹ˆå·¥å…·å¯ä»¥ç”¨å•Šï¼Ÿ\")\n",
    "for chunk in stream:\n",
    "    print(chunk.content, end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "692bc7bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "æˆ‘æ¥å¸®æ‚¨è®¡ç®— 2+2ã€‚\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = llm_with_tools.invoke(\"ä½ è°ƒç”¨å‡½æ•°è®¡ç®—ä¸€ä¸‹ 2+2\")\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "caccd8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = [\"é—®é¢˜1\"]\n",
    "answers = llm.batch(prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2097fa2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æ‚¨å¥½ï¼æˆ‘çœ‹åˆ°æ‚¨æåˆ°äº†â€œé—®é¢˜1â€ï¼Œä½†ä¼¼ä¹æ²¡æœ‰æä¾›å…·ä½“çš„é—®é¢˜å†…å®¹ã€‚ä¸ºäº†æ›´å¥½åœ°å¸®åŠ©æ‚¨ï¼Œè¯·æ‚¨è¯¦ç»†è¯´æ˜ä¸€ä¸‹æ‚¨æƒ³é—®ä»€ä¹ˆé—®é¢˜ã€‚ä¾‹å¦‚ï¼š\n",
      "\n",
      "- æ‚¨æ˜¯æƒ³è®¨è®ºæŸä¸ªç‰¹å®šä¸»é¢˜ï¼ˆå¦‚æŠ€æœ¯ã€ç”Ÿæ´»ã€å­¦ä¹ ç­‰ï¼‰å—ï¼Ÿ\n",
      "- è¿™æ˜¯ä¸€ä¸ªç³»åˆ—é—®é¢˜ä¸­çš„ç¬¬ä¸€ä¸ªå—ï¼Ÿå¦‚æœæœ‰åç»­é—®é¢˜ï¼Œä¹Ÿè¯·ä¸€å¹¶æä¾›ã€‚\n",
      "- æˆ–è€…ï¼Œæ‚¨æ˜¯æƒ³è®©æˆ‘ååŠ©è§£å†³æŸä¸ªå…·ä½“ä»»åŠ¡æˆ–æŸ¥è¯¢ï¼Ÿ\n",
      "\n",
      "è¯·è¡¥å……æ›´å¤šç»†èŠ‚ï¼Œæˆ‘ä¼šå°½å¿«ä¸ºæ‚¨æä¾›è¯¦ç»†çš„è§£ç­”æˆ–å»ºè®®ï¼ ğŸ˜Š\n"
     ]
    }
   ],
   "source": [
    "for answer in answers:\n",
    "    print(answer.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ecbb6141",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è¿™å¥è¯çš„ä¸­æ–‡ç¿»è¯‘æ˜¯ï¼š  \n",
      "**â€œä½ å¥½ï¼Œæœ€è¿‘æ€ä¹ˆæ ·ï¼Ÿâ€**  \n",
      "\n",
      "### ç¿»è¯‘è¯´æ˜ï¼š\n",
      "1. **Hello** â†’ **â€œä½ å¥½â€**  \n",
      "   - è¿™æ˜¯ä¸­æ–‡ä¸­æœ€é€šç”¨çš„é—®å€™è¯­ï¼Œé€‚ç”¨äºæ­£å¼æˆ–éæ­£å¼åœºåˆã€‚\n",
      "2. **how are you?** â†’ **â€œæœ€è¿‘æ€ä¹ˆæ ·ï¼Ÿâ€**  \n",
      "   - å­—é¢ç›´è¯‘æ˜¯â€œä½ å¥½å—ï¼Ÿâ€ï¼Œä½†ä¸­æ–‡æ—¥å¸¸äº¤æµä¸­æ›´å¸¸ç”¨â€œæœ€è¿‘æ€ä¹ˆæ ·ï¼Ÿâ€æ¥è¡¨è¾¾å¯¹è¿‘å†µçš„å…³å¿ƒï¼Œæ›´è‡ªç„¶æµç•…ã€‚\n",
      "\n",
      "### å…¶ä»–å¸¸è§è¯‘æ³•ï¼š\n",
      "- **æ›´ç®€æ´ç‰ˆ**ï¼š  \n",
      "  â€œä½ å¥½å—ï¼Ÿâ€ï¼ˆç›´è¯‘ï¼Œç•¥æ˜¾ç”Ÿç¡¬ï¼Œä½†è¯­æ³•æ­£ç¡®ï¼‰  \n",
      "- **æ›´å£è¯­åŒ–**ï¼š  \n",
      "  â€œå—¨ï¼Œæœ€è¿‘å’‹æ ·ï¼Ÿâ€ï¼ˆé€‚åˆæœ‹å‹ã€ç†Ÿäººä¹‹é—´ï¼‰  \n",
      "- **æ›´æ­£å¼ç‰ˆ**ï¼š  \n",
      "  â€œæ‚¨å¥½ï¼Œä¸€åˆ‡å¯å¥½ï¼Ÿâ€ï¼ˆé€‚ç”¨äºå•†åŠ¡æˆ–é•¿è¾ˆï¼‰\n",
      "\n",
      "æ ¹æ®ä½¿ç”¨åœºæ™¯é€‰æ‹©æœ€åˆé€‚çš„è¡¨è¾¾å³å¯ ğŸ˜Š\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# ç¬¬1æ­¥ï¼šåˆ›å»ºæç¤ºè¯æ¨¡æ¿\n",
    "# è¿™ä¹Ÿæ˜¯ä¸€ä¸ª Runnableï¼Œæœ‰ invokeã€stream ç­‰æ–¹æ³•\n",
    "prompt = ChatPromptTemplate.from_template(\"å°†è¿™å¥è¯ç¿»è¯‘æˆ{target_language}ï¼š{text}\")\n",
    "parser = StrOutputParser()\n",
    "\n",
    "translation_chain = prompt | llm | parser\n",
    "result = translation_chain.invoke(\n",
    "    {\"target_language\": \"ä¸­æ–‡\", \"text\": \"Hello, how are you?\"}\n",
    ")\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7cdf186",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Good morning!\" çš„æ³•è¯­ç¿»è¯‘æ˜¯ï¼š\n",
      "\n",
      "**Bonjour!**\n",
      "\n",
      "### è¡¥å……è¯´æ˜ï¼š\n",
      "1. **ä½¿ç”¨åœºæ™¯**ï¼š  \n",
      "   \"Bonjour\" æ˜¯æ³•è¯­ä¸­æœ€å¸¸ç”¨çš„æ—©æ™¨é—®å€™è¯­ï¼Œé€‚ç”¨äºä»»ä½•åœºåˆï¼ˆæ­£å¼/éæ­£å¼ï¼‰ï¼Œæ—¶é—´èŒƒå›´å¤§çº¦ä»æ—¥å‡ºåˆ°ä¸­åˆï¼ˆçº¦12ç‚¹å‰ï¼‰ã€‚\n",
      "\n",
      "2. **æ–‡åŒ–æç¤º**ï¼š  \n",
      "   åœ¨æ³•å›½ï¼Œ\"Bonjour\" æ˜¯æ—¥å¸¸ç¤¾äº¤çš„å¿…å¤‡ç”¨è¯­ã€‚è¿›å…¥å•†åº—ã€é¤å…æˆ–ä¸äººæ‰“æ‹›å‘¼æ—¶ï¼Œå¿…é¡»å…ˆè¯´ \"Bonjour\"ï¼Œå¦åˆ™å¯èƒ½è¢«è§†ä¸ºæ— ç¤¼ã€‚\n",
      "\n",
      "3. **å…¶ä»–è¡¨è¾¾**ï¼š  \n",
      "   - éå¸¸æ­£å¼åœºåˆï¼ˆå¦‚å•†åŠ¡ä¼šè®®ï¼‰ï¼š**Bonjour Madame / Monsieur**ï¼ˆæ—©ä¸Šå¥½ï¼Œå¥³å£«/å…ˆç”Ÿï¼‰  \n",
      "   - äº²å¯†æœ‹å‹é—´ï¼š**Salut!**ï¼ˆä½ å¥½ï¼Œä½†æ›´é€šç”¨ï¼Œä¸åˆ†æ—©æ™šï¼‰\n",
      "\n",
      "4. **å‘éŸ³**ï¼š  \n",
      "   /bÉ”Ìƒ.Ê’uÊ/ï¼ˆç±»ä¼¼\"å´©æ—¥å‘µ\"ï¼Œ\"r\" å°èˆŒéŸ³ï¼‰\n",
      "\n",
      "### ä¾‹å¥ï¼š\n",
      "- **Good morning! How are you?**  \n",
      "  â†’ Bonjour! Comment allez-vous?  \n",
      "- **Good morning, Mr. Dupont.**  \n",
      "  â†’ Bonjour, Monsieur Dupont.  \n",
      "\n",
      "â˜€ï¸ è®°ä½ï¼šåœ¨æ³•å›½ï¼Œä¸€å¥ \"Bonjour\" æ˜¯å¼€å¯ä»»ä½•äº¤æµçš„é’¥åŒ™ï¼\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "\n",
    "# åˆ›å»ºè‡ªå®šä¹‰å¤„ç†å‡½æ•°\n",
    "def extract_translation(text: str) -> str:\n",
    "    \"\"\"ä»æ¨¡å‹è¾“å‡ºä¸­å»é™¤é¢å¤–çš„å¼•å·å’Œç©ºæ ¼\"\"\"\n",
    "    return text.strip().strip('\"').strip(\"'\")\n",
    "\n",
    "\n",
    "# åˆ›å»º Lambda Runnable\n",
    "cleaner = RunnableLambda(extract_translation)\n",
    "\n",
    "# åœ¨ç®¡é“ä¸­æ’å…¥æ¸…ç†æ­¥éª¤\n",
    "translation_chain = prompt | llm | parser | cleaner\n",
    "\n",
    "result = translation_chain.invoke({\"target_language\": \"æ³•è¯­\", \"text\": \"Good morning!\"})\n",
    "\n",
    "print(result)\n",
    "# å¦‚æœæ¨¡å‹è¾“å‡º \"Bonjour!\" å¸¦å¼•å·ï¼Œcleaner ä¼šå»é™¤å®ƒä»¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c5f04ff9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "é”™è¯¯: ä¸æ”¯æŒçš„è¯­è¨€: dd. æ”¯æŒçš„è¯­è¨€: en, es, fr, de, zh, ja\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "# 1. æ”¯æŒçš„è¯­è¨€\n",
    "SUPPORTED_LANGUAGES = {\n",
    "    \"en\": \"English\",\n",
    "    \"es\": \"Spanish\",\n",
    "    \"fr\": \"French\",\n",
    "    \"de\": \"German\",\n",
    "    \"zh\": \"Chinese\",\n",
    "    \"ja\": \"Japanese\",\n",
    "}\n",
    "\n",
    "\n",
    "# 2. éªŒè¯è¯­è¨€çš„å‡½æ•°\n",
    "def validate_language(language_code: str) -> str:\n",
    "    \"\"\"éªŒè¯è¯­è¨€ä»£ç æ˜¯å¦æ”¯æŒ\"\"\"\n",
    "    if language_code.lower() not in SUPPORTED_LANGUAGES:\n",
    "        raise ValueError(\n",
    "            f\"ä¸æ”¯æŒçš„è¯­è¨€: {language_code}. \"\n",
    "            f\"æ”¯æŒçš„è¯­è¨€: {', '.join(SUPPORTED_LANGUAGES.keys())}\"\n",
    "        )\n",
    "    return SUPPORTED_LANGUAGES[language_code.lower()]\n",
    "\n",
    "\n",
    "# 3. ç¿»è¯‘æç¤ºè¯\n",
    "translation_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ç¿»è¯‘å®¶ã€‚\n",
    "è¯·å°†ä»¥ä¸‹æ–‡æœ¬ç¿»è¯‘æˆ{target_language}ã€‚\n",
    "åªè¾“å‡ºç¿»è¯‘åçš„æ–‡æœ¬ï¼Œä¸éœ€è¦å…¶ä»–è¯´æ˜ã€‚\n",
    "\n",
    "åŸæ–‡ï¼š{text}\n",
    "ç¿»è¯‘ï¼š\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "# 4. è´¨é‡æ£€æŸ¥å‡½æ•°\n",
    "def check_translation_quality(translation: str) -> dict:\n",
    "    \"\"\"æ£€æŸ¥ç¿»è¯‘æ˜¯å¦ä¸ºç©º\"\"\"\n",
    "    if not translation.strip():\n",
    "        raise ValueError(\"ç¿»è¯‘ç»“æœä¸ºç©ºï¼Œè¯·é‡è¯•\")\n",
    "    return {\"translation\": translation, \"quality_check_passed\": True}\n",
    "\n",
    "\n",
    "parser = StrOutputParser()\n",
    "\n",
    "# 6. æ„å»º Pipeline\n",
    "translation_chain = (\n",
    "    # éªŒè¯è¯­è¨€\n",
    "    RunnableLambda(\n",
    "        lambda x: {**x, \"target_language\": validate_language(x[\"language_code\"])}\n",
    "    )\n",
    "    # æç¤ºè¯æ ¼å¼åŒ–\n",
    "    | translation_prompt\n",
    "    # è°ƒç”¨æ¨¡å‹\n",
    "    | llm\n",
    "    # è§£æè¾“å‡º\n",
    "    | parser\n",
    "    # è´¨é‡æ£€æŸ¥\n",
    "    | RunnableLambda(check_translation_quality)\n",
    ")\n",
    "\n",
    "# 7. ä½¿ç”¨ Pipeline\n",
    "try:\n",
    "    result = translation_chain.invoke(\n",
    "        {\"language_code\": \"dd\", \"text\": \"The quick brown fox jumps over the lazy dog\"}\n",
    "    )\n",
    "    print(f\"ç¿»è¯‘ç»“æœ: {result['translation']}\")\n",
    "except ValueError as e:\n",
    "    print(f\"é”™è¯¯: {e}\")\n",
    "\n",
    "# è¾“å‡ºï¼š\n",
    "# ç¿»è¯‘ç»“æœ: El rÃ¡pido zorro marrÃ³n salta sobre el perro perezoso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "25c64933",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== æµå¼ç¿»è¯‘ ===\n",
      "LangChain est incroyable !\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1. æµå¼è¾“å‡ºï¼ˆé€å­—è¾“å‡ºï¼‰\n",
    "print(\"=== æµå¼ç¿»è¯‘ ===\")\n",
    "for chunk in translation_chain.stream(\n",
    "    {\"language_code\": \"fr\", \"text\": \"LangChain is amazing!\"}\n",
    "):\n",
    "    if isinstance(chunk, dict):\n",
    "        print(chunk[\"translation\"], end=\"\", flush=True)\n",
    "    else:\n",
    "        print(chunk, end=\"\", flush=True)\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "# 3. å¼‚æ­¥è°ƒç”¨ï¼ˆéé˜»å¡ï¼‰\n",
    "\n",
    "\n",
    "async def async_translate():\n",
    "    result = await translation_chain.ainvoke(\n",
    "        {\"language_code\": \"zh\", \"text\": \"Artificial Intelligence\"}\n",
    "    )\n",
    "    return result\n",
    "\n",
    "\n",
    "# åœ¨å¼‚æ­¥ä¸Šä¸‹æ–‡ä¸­è¿è¡Œ\n",
    "# result = asyncio.run(async_translate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f4bb0840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "åŸæ–‡: Machine learning is a subset of artificial intelligence\n",
      "ç¿»è¯‘: **Translation:**  \n",
      "\"Aprendizaje automÃ¡tico es un subconjunto de inteligencia artificial.\"  \n",
      "\n",
      "### Notes:\n",
      "1. **\"Machine learning\"** se traduce como **\"aprendizaje automÃ¡tico\"** (tÃ©rmino estÃ¡ndar en espaÃ±ol, reconocido por la RAE).  \n",
      "2. **\"Subset\"** se traduce como **\"subconjunto\"** (tÃ©rmino matemÃ¡tico/tecnolÃ³gico comÃºn).  \n",
      "3. **\"Artificial intelligence\"** se traduce como **\"inteligencia artificial\"**.  \n",
      "4. La estructura gramatical en espaÃ±ol mantiene el orden lÃ³gico del original, usando \"es\" para \"is\".  \n",
      "5. No se usan mayÃºsculas en los tÃ©rminos tÃ©cnicos (excepto al inicio de la oraciÃ³n), ya que no son nombres propios.\n",
      "è¯„åˆ†: 10/10\n",
      "åé¦ˆ: La traducciÃ³n es impecable. Utiliza tÃ©rminos tÃ©cnicos estÃ¡ndar en espaÃ±ol reconocidos por la RAE ('aprendizaje automÃ¡tico', 'subconjunto', 'inteligencia artificial'), mantiene la estructura gramatical lÃ³gica del original, y respeta las convenciones de capitalizaciÃ³n del espaÃ±ol. La traducciÃ³n es precisa, natural y completa.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser, StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "# 1. ç¿»è¯‘é˜¶æ®µ\n",
    "translation_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "Translate the following text to {target_language}:\n",
    "Text: {text}\n",
    "Translation:\n",
    "\"\"\")\n",
    "\n",
    "translator = translation_prompt | llm | StrOutputParser()\n",
    "\n",
    "# 2. è¯„ä¼°é˜¶æ®µ\n",
    "evaluation_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "Please evaluate this translation:\n",
    "Original: {original_text}\n",
    "Translation: {translated_text}\n",
    "Target Language: {target_language}\n",
    "\n",
    "Provide your evaluation in JSON format with:\n",
    "- accuracy (1-10)\n",
    "- naturalness (1-10)\n",
    "- completeness (1-10)\n",
    "- overall_quality (1-10)\n",
    "- feedback (string)\n",
    "\n",
    "JSON:\n",
    "\"\"\")\n",
    "\n",
    "evaluator = evaluation_prompt | llm | JsonOutputParser()\n",
    "\n",
    "\n",
    "# 3. å®Œæ•´æµç¨‹\n",
    "def full_translation_pipeline(original_text: str, target_language: str) -> dict:\n",
    "    \"\"\"ç¿»è¯‘ + è¯„ä¼°\"\"\"\n",
    "\n",
    "    # ç¿»è¯‘\n",
    "    translated_text = translator.invoke(\n",
    "        {\"target_language\": target_language, \"text\": original_text}\n",
    "    )\n",
    "\n",
    "    # è¯„ä¼°\n",
    "    evaluation = evaluator.invoke(\n",
    "        {\n",
    "            \"original_text\": original_text,\n",
    "            \"translated_text\": translated_text,\n",
    "            \"target_language\": target_language,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # è¿”å›å®Œæ•´ç»“æœ\n",
    "    return {\n",
    "        \"original\": original_text,\n",
    "        \"translated\": translated_text,\n",
    "        \"language\": target_language,\n",
    "        \"evaluation\": evaluation,\n",
    "    }\n",
    "\n",
    "\n",
    "# 4. ä½¿ç”¨\n",
    "result = full_translation_pipeline(\n",
    "    \"Machine learning is a subset of artificial intelligence\", \"Spanish\"\n",
    ")\n",
    "\n",
    "print(f\"åŸæ–‡: {result['original']}\")\n",
    "print(f\"ç¿»è¯‘: {result['translated']}\")\n",
    "print(f\"è¯„åˆ†: {result['evaluation']['overall_quality']}/10\")\n",
    "print(f\"åé¦ˆ: {result['evaluation']['feedback']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "notebooks",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
